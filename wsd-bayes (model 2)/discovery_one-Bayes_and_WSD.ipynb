{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16dddf48-2098-4933-95b5-b64a1289b918",
   "metadata": {},
   "source": [
    "# Discovery One\n",
    "## Twitter Disaster Prediction NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3347e269-813b-48be-afb1-7d0cdbb26fc1",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbdeb4f-0090-440d-8cbe-6212a477ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import string\n",
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm-2.3.1\", disable=[\"tagger\", \"parser\", \"ner\"])\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49e4b8d-1f9b-4075-b781-cb7584f1961b",
   "metadata": {},
   "source": [
    "# Word Sense Disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d290369-54ba-44a6-8de2-6b10c251742d",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259aee84-5ccd-4ee2-9754-489b751ee260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, truth=0):\n",
    "    x = []\n",
    "    y = []\n",
    "    df = pd.read_csv(path)\n",
    "    for i in df.index:\n",
    "        x.append(df.at[i, \"text\"])\n",
    "        if truth:\n",
    "            y.append(df.at[i, \"target\"])\n",
    "    return x, y\n",
    "\n",
    "def load_data_indices(path, truth=0):\n",
    "    x = []\n",
    "    y = []\n",
    "    df = pd.read_csv(path)\n",
    "    for i in df.index:\n",
    "        x.append((df.at[i,\"id\"],df.at[i, \"text\"]))\n",
    "        if truth:\n",
    "            y.append(df.at[i, \"target\"])\n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = load_data(\"train.csv\",1)\n",
    "x_train_indices, _ = load_data_indices(\"train.csv\")\n",
    "x_test, _ = load_data(\"test.csv\")\n",
    "x_test_indices, _ = load_data_indices(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3bd93e-e490-4615-ae6b-c9e15dc5f403",
   "metadata": {},
   "source": [
    "### Create a y_test array\n",
    "I am using a test_predictions file to inner merge on ids with the ground truth file. This will get rid of any ids in the ground truth file that are used in our training set.\n",
    "\n",
    "Then I will take the target_groundtruth column from the merged dataframe, and place that array into the variable y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45afa4a4-0074-452d-b99e-0269945b3af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the predicted file\n",
    "df_test = pd.read_csv('test_predictions_cv.csv')\n",
    "df_groundtruth = pd.read_csv('ground_truth.csv')\n",
    "\n",
    "# Merge the DataFrames on 'id' column to have a single DataFrame for comparison\n",
    "merged_df = pd.merge(df_test, df_groundtruth, on='id', suffixes=('_predicted', '_groundtruth'))\n",
    "y_test = merged_df.iloc[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59aa93d-b151-4196-a35c-d52f9f4b5f6f",
   "metadata": {},
   "source": [
    "### Strip punctuation and get word features\n",
    "\n",
    "I am using the string package to strip punctuate marks, and a regex to get rid of any http/com data.\n",
    "\n",
    "Then I clean the words, creating a new variable to hold the cleaned individual words, before combining into a final array of all the words in the data.\n",
    "\n",
    "Finally, I flatten the 2D array in order to find the frequency of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bdda35-ff0d-4a2d-b067-09b24d5c555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function to clean HTML tags and perform basic cleanup\n",
    "def preprocessor(text):\n",
    "    html_regex = \"<[^>]*>*<[^>]*>\"\n",
    "    if type(text) == str:\n",
    "        text = re.sub(html_regex, \"\", text)\n",
    "        text = re.sub(\"[\\W]+\", \"\", text.lower())\n",
    "    return text\n",
    "\n",
    "# Function to tokenize, remove stop words, and lemmatize\n",
    "def tokenize(doc):\n",
    "    tokens = nlp(doc)\n",
    "    return [preprocessor(token.lemma_) for token in tokens if not token.is_stop]\n",
    "\n",
    "# Applying preprocessing steps to x_train and x_test\n",
    "all_words_xtrain = [tokenize(doc) for doc in x_train]\n",
    "all_words_xtest = [tokenize(doc) for doc in x_test]\n",
    "\n",
    "cleaned_words = all_words_xtrain+all_words_xtest\n",
    "\n",
    "# Printing the first sentence's cleaned words\n",
    "print(cleaned_words[0])\n",
    "\n",
    "# Flatten the 2D array to get a list of all words\n",
    "flattened_words = [word for sublist in cleaned_words for word in sublist]\n",
    "\n",
    "# Count the frequency of each word\n",
    "all_words = nltk.FreqDist(flattened_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeaff45-4f48-431a-bd15-8335d89dc835",
   "metadata": {},
   "source": [
    "#### Create feature sets for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a854c7-96f8-419c-b019-0127175099f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document_words):\n",
    "    features = {word: (word in document_words) for word in word_features}\n",
    "    return features\n",
    "word_features = list(all_words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8fee95-e7df-4237-aefc-be83c38794af",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_train = list(zip(all_words_xtrain, y_train))\n",
    "    \n",
    "training_set = [(find_features(words), label) for (words, label) in documents_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd96302-ee16-4e0b-9113-b2384d3d2faa",
   "metadata": {},
   "source": [
    "#### Create feature sets for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b10322-84d7-4bfc-a477-de25d9cc1256",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_test = list(zip(all_words_xtest, y_test))\n",
    "\n",
    "testing_set = [(find_features(words), label) for (words, label) in documents_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf7930c-87ea-42ca-8a3b-60514de719d4",
   "metadata": {},
   "source": [
    "#### Prediction Grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338cdd74-569c-45b0-94c6-a95a1ab62721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(predictions, ground_truth):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    # Iterate through the merged DataFrame to compare targets\n",
    "    for pred, truth in zip(predictions, ground_truth):\n",
    "            if pred == 1 and truth == 1:\n",
    "                tp += 1\n",
    "            elif pred == 0 and truth == 0:\n",
    "                tn += 1\n",
    "            elif pred == 1 and truth == 0:\n",
    "                fp += 1\n",
    "            elif pred == 0 and truth == 1:\n",
    "                fn += 1\n",
    "\n",
    "    # Print the counts of TP, FP, TN, FN\n",
    "    print(f\"True Positives (TP): {tp}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Negatives (FN): {fn}\")\n",
    "    print(f\"Precision (TP/TP+FP): {tp/(tp+fp)}\")\n",
    "    print(f\"Recall (TP/TP+FN): {tp/(tp+fn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fef5e3-6b24-4be8-a326-c16b56bc0dfe",
   "metadata": {},
   "source": [
    "### WSD with Naive Bayes\n",
    "\n",
    "In this section I am training the Naive Bayes Classifier on the training set.\n",
    "\n",
    "I am saving the classifier as a pickle file so that I do not have to retrain every time I want to look at predictions for the testing data.\n",
    "\n",
    "In order to train the classifier over again (for instance if you are changing the training set or modifying the options) you must delete the appropriate pickle file.\n",
    "\n",
    "This process will take quite a bit of time (>5 minutes), even using maximum cores and RAM from Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc502a-db54-438e-9d1a-b88a825501bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"naivebayes.pickle\"):\n",
    "    # If the pickle exists, load and use it\n",
    "    with open(\"naivebayes.pickle\", \"rb\") as classifier_f:\n",
    "        classifier = pickle.load(classifier_f)\n",
    "else:\n",
    "    # If the pickle doesn't exist, retrain the classifier and save it\n",
    "    classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "    with open(\"naivebayes.pickle\", \"wb\") as save_classifier:\n",
    "        pickle.dump(classifier, save_classifier)\n",
    "        \n",
    "test_predictions = [classifier.classify(features) for features, label in testing_set]  \n",
    "accuracy = nltk.classify.accuracy(classifier, testing_set)\n",
    "print(\"Naive Bayes Classifier accuracy percent:\",(accuracy*100))\n",
    "evaluate_predictions(test_predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74069876-62f8-42ad-bb55-c42a863a108d",
   "metadata": {},
   "source": [
    "### WSD with MultinomialNB\n",
    "\n",
    "In this section, I am training another Naive Bayes classifier from within the SKLearnClassifier package, Multionmial Naive Bayes\n",
    "The accuracy is slightly better with this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd579fa0-b40e-4d21-b8a6-6dbebf6a3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"MNB_classifier.pickle\"):\n",
    "    # If the pickle exists, load and use it\n",
    "    with open(\"MNB_classifier.pickle\", \"rb\") as classifier_f:\n",
    "        MNB_classifier = pickle.load(classifier_f)\n",
    "else:\n",
    "    # If the pickle doesn't exist, retrain the classifier and save it\n",
    "    MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "    MNB_classifier.train(training_set)\n",
    "    with open(\"MNB_classifier.pickle\", \"wb\") as save_classifier:\n",
    "        pickle.dump(MNB_classifier, save_classifier)\n",
    "        \n",
    "test_predictions_MNB = [MNB_classifier.classify(features) for features, label in testing_set]  \n",
    "accuracy_MNB = nltk.classify.accuracy(MNB_classifier, testing_set)\n",
    "print(\"MultinomialNB accuracy percent:\", accuracy_MNB*100)\n",
    "evaluate_predictions(test_predictions_MNB, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spacy_env_mgriffin)",
   "language": "python",
   "name": "spacy_env_mgriffin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
